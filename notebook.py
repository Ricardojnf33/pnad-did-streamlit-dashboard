# -*- coding: utf-8 -*-
"""Untitled139.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YTZ7xIp8BAUG88-u0iRjou6Epip537pE

# AnÃ¡lise Causal: O Impacto da Escola em Tempo Integral na Renda e Emprego

**Autor:** Seu Nome
**Data:** 15 de julho de 2025

## 1. Entendimento do NegÃ³cio e da QuestÃ£o Causal

Este notebook implementa uma anÃ¡lise de inferÃªncia causal para estimar o impacto da expansÃ£o das Escolas de Tempo Integral (ETI) no Brasil sobre os resultados dos jovens no mercado de trabalho.

**Objetivo:** Ir alÃ©m da correlaÃ§Ã£o e estimar o **efeito causal** de frequentar uma ETI na probabilidade de emprego formal e na renda de jovens adultos.

**Metodologia:** Utilizaremos um modelo de **DiferenÃ§as em DiferenÃ§as (DiD)**, aplicando-o a um painel de dados construÃ­do a partir dos microdados da PNAD ContÃ­nua. Esta abordagem nos permite simular um experimento, comparando a trajetÃ³ria de resultados de um "grupo de tratamento" (exposto Ã  polÃ­tica) com um "grupo de controle".

**Estrutura CRISP-DM:**
1.  **Entendimento do NegÃ³cio:** Definir a questÃ£o causal.
2.  **Entendimento dos Dados:** Explorar a PNAD ContÃ­nua.
3.  **PreparaÃ§Ã£o dos Dados:** Limpar, transformar e construir o painel.
4.  **Modelagem:** Estimar o modelo DiD e validar suas premissas.
5.  **AvaliaÃ§Ã£o:** Interpretar os resultados e suas limitaÃ§Ãµes.
6.  **ImplantaÃ§Ã£o:** Preparar os dados para um dashboard em Streamlit.
"""

# InstalaÃ§Ã£o das bibliotecas necessÃ¡rias para o projeto.
# - pandas: para manipulaÃ§Ã£o e anÃ¡lise de dados.
# - statsmodels: para modelos estatÃ­sticos, incluindo regressÃ£o com pesos e erros clusterizados.
# - plotnine: para visualizaÃ§Ãµes de dados elegantes baseadas na "grammar of graphics".
# - basedosdados: para facilitar o acesso a dados pÃºblicos brasileiros (alternativa ao download manual).

print("Instalando bibliotecas...")
!pip install pandas statsmodels plotnine basedosdados -q
print("InstalaÃ§Ã£o concluÃ­da.")

import pandas as pd
import numpy as np
import statsmodels.api as sm
import statsmodels.formula.api as smf
from plotnine import ggplot, aes, geom_line, geom_vline, labs, theme_minimal, scale_color_manual, geom_ribbon
import basedosdados as bd
import warnings

# ConfiguraÃ§Ãµes de visualizaÃ§Ã£o e avisos
warnings.filterwarnings('ignore')
pd.set_option('display.float_format', lambda x: '%.3f' % x)

print("Bibliotecas importadas com sucesso.")

# Substitua pelo ID do seu projeto no Google Cloud Platform
BILLING_PROJECT_ID = "gen-lang-client-0926041388"

# Query para selecionar as variÃ¡veis de interesse da PNAD ContÃ­nua de 2016 a 2023 (4Âº trimestre de cada ano)
query = """
SELECT
    ano,
    sigla_uf,
    V2009 AS idade,
    V2007 AS sexo,
    V2010 AS cor_raca,
    V1028 AS peso_amostral,
    VD4002 AS condicao_ocupacao,
    VD4035 AS rendimento_trabalho_habitual
FROM
    `basedosdados.br_ibge_pnadc.microdados`
WHERE
    ano BETWEEN 2016 AND 2023
    AND trimestre = 4
    AND V2009 BETWEEN 20 AND 25
"""

print("Carregando dados da PNADc... Isso pode levar alguns minutos.")
df_pnad = bd.read_sql(query, billing_project_id=BILLING_PROJECT_ID)
print("Dados carregados com sucesso!")
print(f"DimensÃµes do DataFrame: {df_pnad.shape}")
df_pnad.head(100)

df_pnad.head(100)

"""## 3. PreparaÃ§Ã£o dos Dados

Esta Ã© a fase mais crÃ­tica. Aqui, vamos:
1.  Limpar os dados e criar as variÃ¡veis de resultado.
2.  Definir os grupos de tratamento e controle de forma simulada, como seria feito ao cruzar com dados do Censo Escolar.
3.  Criar as variÃ¡veis `treat`, `post` e a interaÃ§Ã£o `did_interaction`.

* Limpeza e CriaÃ§Ã£o de VariÃ¡veis
"""

# Copiando para evitar SettingWithCopyWarning
df_prep = df_pnad.copy()

# 1. Criar variÃ¡vel de resultado: Emprego Formal
# VD4002 == 1 significa "Ocupado"
df_prep['emprego_formal'] = np.where(df_prep['condicao_ocupacao'] == 1, 1, 0)

# 2. Criar variÃ¡vel de resultado: Log da Renda
# Removemos valores nulos e rendas iguais a zero para aplicar o log
df_prep = df_prep.dropna(subset=['rendimento_trabalho_habitual'])
df_prep = df_prep[df_prep['rendimento_trabalho_habitual'] > 0]
df_prep['log_renda'] = np.log(df_prep['rendimento_trabalho_habitual'])

# 3. SimulaÃ§Ã£o da DefiniÃ§Ã£o dos Grupos de Tratamento e Controle
# Em um projeto real, cruzarÃ­amos com dados do Censo Escolar por UF.
# Aqui, vamos SIMULAR que um grupo de estados (ex: Nordeste) expandiu as ETIs ("tratamento")
# e outro grupo (ex: Sul) nÃ£o ("controle").
estados_tratamento = ['MA', 'PI', 'CE', 'RN', 'PB', 'PE', 'AL', 'SE', 'BA']
estados_controle = ['PR', 'SC', 'RS']

# Filtrar o dataframe para incluir apenas os estados definidos
df_prep = df_prep[df_prep['sigla_uf'].isin(estados_tratamento + estados_controle)]

# Criar a variÃ¡vel 'treat'
df_prep['treat'] = np.where(df_prep['sigla_uf'].isin(estados_tratamento), 1, 0)

# 4. Criar a variÃ¡vel 'post' (pÃ³s-tratamento)
# Definimos o ano de inÃ­cio da polÃ­tica como 2020
df_prep['post'] = np.where(df_prep['ano'] >= 2020, 1, 0)

# 5. Selecionar colunas finais
colunas_finais = ['ano', 'sigla_uf', 'log_renda', 'emprego_formal', 'treat', 'post', 'idade', 'sexo', 'cor_raca', 'peso_amostral']
df_clean = df_prep[colunas_finais].dropna()

print("Dados preparados para anÃ¡lise.")
print(f"DimensÃµes finais: {df_clean.shape}")
df_clean.head()

"""## 4. Modelagem: Validando a Premissa Crucial

Antes de estimar o modelo, precisamos verificar a premissa mais importante do DiD: as **tendÃªncias paralelas**. Ela assume que, na ausÃªncia da polÃ­tica, os grupos de tratamento e controle teriam seguido trajetÃ³rias paralelas.

Vamos visualizar as tendÃªncias da `log_renda` mÃ©dia para ambos os grupos no perÃ­odo **prÃ©-tratamento** (2016-2019).

* VisualizaÃ§Ã£o das TendÃªncias Paralelas
"""

# Calcular a mÃ©dia ponderada da log_renda por ano e grupo
df_trends = df_clean.copy()
df_trends['renda_ponderada'] = df_trends['log_renda'] * df_trends['peso_amostral']

summary_trends = df_trends.groupby(['ano', 'treat']) \
                          .agg(renda_ponderada_sum=('renda_ponderada', 'sum'),
                               peso_sum=('peso_amostral', 'sum')) \
                          .reset_index()

summary_trends['log_renda_media'] = summary_trends['renda_ponderada_sum'] / summary_trends['peso_sum']

# GrÃ¡fico de TendÃªncias Paralelas
plot_trends = (
    ggplot(summary_trends, aes(x='ano', y='log_renda_media', color='factor(treat)'))
    + geom_line(size=1.5)
    + geom_vline(xintercept=2019.5, linetype='dashed', color='red', size=1)
    + labs(
        title="VerificaÃ§Ã£o da Premissa de TendÃªncias Paralelas (PerÃ­odo PrÃ©-Tratamento)",
        subtitle="Log da Renda MÃ©dia Ponderada (2016-2023)",
        x="Ano",
        y="Log da Renda MÃ©dia",
        color="Grupo"
    )
    + theme_minimal()
    + scale_color_manual(values=['#0072B2', '#D55E00'], labels=['Controle', 'Tratamento'])
)

print(plot_trends)

"""### Implementando o Modelo de DiferenÃ§as em DiferenÃ§as

Com evidÃªncias visuais de que as tendÃªncias sÃ£o razoavelmente paralelas no perÃ­odo prÃ©-tratamento, podemos prosseguir com a estimaÃ§Ã£o do modelo de regressÃ£o.

A equaÃ§Ã£o Ã©:
$$Y_{it} = \beta_0 + \beta_1 \cdot \text{Treat}_i + \beta_2 \cdot \text{Post}_t + \delta \cdot (\text{Treat}_i \times \text{Post}_t) + \gamma \cdot X_{it} + \epsilon_{it}$$

O coeficiente de interesse Ã© **Î´ (delta)**, associado Ã  variÃ¡vel de interaÃ§Ã£o `treat:post`. Ele captura o efeito causal da polÃ­tica.

**Importante:** Usaremos RegressÃ£o Ponderada (WLS) para incorporar os pesos amostrais da PNAD e calcularemos erros-padrÃ£o clusterizados por UF para corrigir a correlaÃ§Ã£o intra-grupo.

* EstimaÃ§Ã£o do Modelo DiD
"""

# FÃ³rmula do modelo DiD com covariÃ¡veis
# C() trata as variÃ¡veis como categÃ³ricas
formula_did = 'log_renda ~ treat * post + idade + C(sexo) + C(cor_raca)'

# EstimaÃ§Ã£o do modelo WLS (Weighted Least Squares)
# cov_type='cluster' e cov_kwds={'groups': df_clean['UF']} sÃ£o cruciais para erros-padrÃ£o corretos
did_model = smf.wls(
    formula=formula_did,
    data=df_clean,
    weights=df_clean['peso_amostral']
).fit(
    cov_type='cluster',
    cov_kwds={'groups': df_clean['sigla_uf']}
)

# Exibindo os resultados
print("--- RESULTADOS DO MODELO DE DIFERENÃ‡AS EM DIFERENÃ‡AS (DiD) ---")
print(did_model.summary())

"""## 5. AvaliaÃ§Ã£o dos Resultados

O coeficiente da interaÃ§Ã£o `treat:post` Ã© o nosso **estimador DiD**.

**InterpretaÃ§Ã£o:**
* **Coeficiente (`coef`):** O valor estimado para `treat:post` (Î´) representa a mudanÃ§a percentual na renda causada pela polÃ­tica. Se for 0.08, por exemplo, indica um aumento de aproximadamente 8% na renda para o grupo tratado.
* **SignificÃ¢ncia EstatÃ­stica (`P>|z|`):** Um valor-p baixo (tipicamente < 0.05) sugere que o efeito estimado nÃ£o Ã© apenas ruÃ­do estatÃ­stico.
* **Intervalo de ConfianÃ§a (`[0.025, 0.975]`):** Fornece uma faixa de valores plausÃ­veis para o efeito real. Se o intervalo nÃ£o inclui o zero, reforÃ§a a conclusÃ£o de que o efeito Ã© estatisticamente significativo.

## 6. ImplantaÃ§Ã£o: Salvando Dados para o Dashboard

A anÃ¡lise estÃ¡ completa. O passo final no notebook Ã© salvar o dataframe limpo e processado. Este arquivo serÃ¡ a fonte de dados para nosso dashboard interativo em Streamlit.

* Salvando o Arquivo Final
"""

# Salvar o dataframe limpo para ser usado no aplicativo Streamlit
output_filename = 'pnad_did_para_dashboard.csv'
df_clean.to_csv(output_filename, index=False)

print(f"Arquivo '{output_filename}' salvo com sucesso!")

"""# ConstruÃ§Ã£o do Dashboard Profissional com Streamlit
Agora, vamos criar o dashboard. Crie uma pasta no seu computador para o projeto. Dentro dela, crie um arquivo chamado app.py e uma subpasta chamada pages.

Estrutura de Arquivos:

Projeto_did_PNAD/
â”‚
â”œâ”€â”€ app.py                  # PÃ¡gina principal do dashboard
â”œâ”€â”€ pnad_did_para_dashboard.csv  # Os dados que vocÃª salvou do Colab
â”‚
â””â”€â”€ pages/
    â”œâ”€â”€ 1_ðŸ“Š_AnÃ¡lise_Descritiva.py
    â””â”€â”€ 2_ðŸ’¡_O_Efeito_Causal.py
Arquivo app.py (PÃ¡gina Principal)

"""

import streamlit as st
import pandas as pd
import plotly.express as px

# --- ConfiguraÃ§Ã£o da PÃ¡gina ---
st.set_page_config(
    page_title="AnÃ¡lise Causal | ETI",
    page_icon="ðŸŽ“",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Carregamento dos Dados ---
@st.cache_data
def load_data():
    return pd.read_csv('pnad_did_para_dashboard.csv')

df = load_data()

# --- Barra Lateral ---
st.sidebar.title("Sobre o Projeto")
st.sidebar.info(
    """
    Este dashboard apresenta uma anÃ¡lise de **inferÃªncia causal** sobre o impacto
    das Escolas de Tempo Integral (ETI) na renda de jovens adultos no Brasil.

    A anÃ¡lise utiliza um modelo de **DiferenÃ§as em DiferenÃ§as (DiD)**
    com microdados da PNAD ContÃ­nua (2016-2023).

    **Navegue pelas pÃ¡ginas para explorar a anÃ¡lise.**
    """
)
st.sidebar.markdown("---")
st.sidebar.write("Desenvolvido com base em metodologias de nÃ­vel PhD.")

# --- ConteÃºdo da PÃ¡gina Principal ---
st.title("ðŸŽ“ Impacto Causal da Escola em Tempo Integral")
st.markdown("### Uma avaliaÃ§Ã£o de polÃ­ticas pÃºblicas atravÃ©s da ciÃªncia de dados")
st.markdown("---")

st.header("O Desafio: Medir o Verdadeiro Impacto de uma PolÃ­tica")
st.markdown(
    """
    O Brasil tem investido na expansÃ£o das **Escolas de Tempo Integral (ETI)** como uma
    estratÃ©gia para melhorar a educaÃ§Ã£o e os resultados futuros dos alunos. Mas como saber
    se o programa realmente funciona?

    Uma simples comparaÃ§Ã£o entre ex-alunos de ETI e de escolas de tempo parcial pode ser enganosa.
    Alunos mais motivados ou de famÃ­lias com mais recursos podem ter maior probabilidade de se matricular
    em uma ETI, e esses fatores, nÃ£o a escola em si, poderiam explicar seu sucesso futuro.
    Isso Ã© o que chamamos de **viÃ©s de seleÃ§Ã£o**.

    Para superar esse desafio, usamos uma abordagem quasi-experimental chamada **DiferenÃ§as em DiferenÃ§as (DiD)**.
    Esta tÃ©cnica nos permite isolar o **efeito causal** da polÃ­tica, nos aproximando de uma resposta confiÃ¡vel.
    """
)

st.image(
    "https://placehold.co/1200x400/0072B2/FFFFFF?text=Visualiza%C3%A7%C3%A3o+da+Narrativa+Causal",
    caption="A jornada da correlaÃ§Ã£o para a causalidade."
)

st.info("Use o menu Ã  esquerda para navegar pelas etapas da nossa anÃ¡lise.", icon="ðŸ‘ˆ")

!streamlit run app.py

